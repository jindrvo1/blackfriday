{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objects import Figure\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from tgmblackfriday import BlackFridayDataset, EncodingType\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoding = {\n",
    "    'Age': EncodingType.ONE_HOT,\n",
    "    'Occupation': EncodingType.ORDINAL,\n",
    "    'Gender': EncodingType.BINARY,\n",
    "    'City_Category': EncodingType.ONE_HOT,\n",
    "    'Product_Category': EncodingType.ONE_HOT\n",
    "}\n",
    "\n",
    "dataset = BlackFridayDataset('data/train.csv', test_path='data/test.csv')\n",
    "df, df_test = dataset.get_dfs()\n",
    "df_encoded, _ = dataset.preprocess_dfs(features_encoding, return_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['User_ID', 'Product_ID']\n",
    "target_col = 'Purchase'\n",
    "product_category_cols = ['Product_Category_1', 'Product_Category_2', 'Product_Category_3']\n",
    "feature_cols = ['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that unique values of all features do not differ between train and test\n",
    "This is necessary for data encoding. If the test dataset included values not seen in the train dataset, encoding would fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_compare = df_test.drop(columns=cols_to_drop + product_category_cols).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_to_compare:\n",
    "    assert set(df[col].unique()) == set(df_test[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = np.unique(df[product_category_cols].values.flatten())\n",
    "df_categories = set(df_categories[~np.isnan(df_categories)])\n",
    "\n",
    "df_test_categories = np.unique(df_test[product_category_cols].values.flatten())\n",
    "df_test_categories = set(df_test_categories[~np.isnan(df_test_categories)])\n",
    "\n",
    "assert len(df_test_categories - df_categories) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_categories - df_test_categories)\n",
    "print(df_test_categories - df_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two missing product categories in the test dataset, but all of the product categories in the test dataset are present in the train dataset, hence this will not cause any problems with data encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between the feature variables and the target variable\n",
    "\n",
    "Since our feature variables are discrete and unordered (except for possibly `Age` and `Stay_In_Current_City_Years`), traditional correlation methods are not suitable. For example, Pearson's correlation assumes that the data are continuous, while Spearman's correlation assumes order in the categorical data.\n",
    "\n",
    "Instead, we measure the correlations using the $\\eta^2$ method based on the ANOVA test, outputting a coefficient in the range of 0 and 1 with higher value indicating stronger association. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "cols = feature_cols + product_category_cols\n",
    "\n",
    "df_correlations = pd.DataFrame(columns=['Feature', 'Correlation'], index=range(len(cols)))\n",
    "\n",
    "for i, feature in enumerate(feature_cols + product_category_cols):\n",
    "    df_rel = df[[feature, 'Purchase']]\n",
    "    model = ols(f'Purchase ~ C({feature})', data=df_rel).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    eta_squared_category1 = anova_table['sum_sq'][f'C({feature})'] / anova_table['sum_sq'].sum()\n",
    "    df_correlations.iloc[i] = [feature, eta_squared_category1]\n",
    "\n",
    "df_correlations = df_correlations.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There don't seem to be significant correlations between the demographic features and the purchase amount, while there is some level of association between the product categories and the target variable. This result is to be investigated further as we don't have much insight into the data, and knowing whether there is an ordinal relationship among the categories will help us choose the correct way to encode it, hence improving the model's performance.\n",
    "\n",
    "Nevertheless, all of the features will be studied more thoroughly to further understand the data to help confirm or reject the correlation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We investigate each of the demographic features. \n",
    "\n",
    "Namely, we are interested in the following:\n",
    "- The distribution of the values (i.e. is the distribution equal or does one value dominate?).\n",
    "- The relationship among the values (i.e. are the values ordinal?). \n",
    "- The relation between the feature values and the purchase variable (i.e. do the purchase amounts differ among different feature values?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_dem_feature(df: pd.DataFrame, feature: str) -> tuple[Figure, Figure, float, float]:\n",
    "    distribution_of_values_fig = px.histogram(df.sort_values(by=feature), x=feature)\n",
    "    distribution_of_values_fig.update_layout(\n",
    "        xaxis_title=f'{feature} group',\n",
    "        yaxis_title='Number of occurrences',\n",
    "    )\n",
    "\n",
    "    purchase_relation_fig = px.box(df.sort_values(by=feature), x=feature, y='Purchase')\n",
    "    purchase_relation_fig.update_layout(\n",
    "        xaxis_title=f'{feature} group',\n",
    "        yaxis_title='Purchase amount',\n",
    "    )\n",
    "\n",
    "    feature_ordered = {val: i for i, val in enumerate(sorted(df[feature].unique()))}\n",
    "\n",
    "    ordinal_mi = mutual_info_regression(\n",
    "        df[[feature]].map(lambda val: feature_ordered[val]),\n",
    "        df['Purchase'],\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    onehot_mi = mutual_info_regression(\n",
    "        pd.get_dummies(df[feature], dtype=int, drop_first=True),\n",
    "        df['Purchase'],\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    return distribution_of_values_fig, purchase_relation_fig, ordinal_mi[0], onehot_mi.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_features_stats_df = pd.DataFrame(columns=['Ordinal MI', 'One-hot MI', 'Correlation'], index=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Gender'\n",
    "dist_fig, relation_fig, ordinal_mi, onehot_mi = investigate_dem_feature(df, feature)\n",
    "dem_features_stats_df.loc[feature] = [ordinal_mi, onehot_mi, df_correlations[df_correlations[\"Feature\"] == feature][\"Correlation\"].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ordinal MI: {ordinal_mi}')\n",
    "print(f'One-hot MI: {onehot_mi}')\n",
    "print(f'Correlation: {dem_features_stats_df.loc[feature][\"Correlation\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Men are represented 3 times more in the dataset. This could lead to potential biases in the model.\n",
    "- Gender does not seem to influence purchase amount.\n",
    "- As this variable is binary, mutual information tests expectedly produced the same values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Age'\n",
    "dist_fig, relation_fig, ordinal_mi, onehot_mi = investigate_dem_feature(df, feature)\n",
    "dem_features_stats_df.loc[feature] = [ordinal_mi, onehot_mi, df_correlations[df_correlations[\"Feature\"] == feature][\"Correlation\"].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ordinal MI: {ordinal_mi}')\n",
    "print(f'One-hot MI: {onehot_mi}')\n",
    "print(f'Correlation: {dem_features_stats_df.loc[feature][\"Correlation\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The distribution of values follows a somewhat normal distribution around the age group of 26-35. This is an expected result.\n",
    "- The purchase amounts do not really differ based on age group.\n",
    "- Intuitively, the `Age` variable is an ordinal variable. However, based on the mutual information tests, one-hot encoding might be a slightly better option for the model training. This indicates that the `Age` variable is not in an ordinal relationship with the target value, so for our data, it might be better to encode the feature without ordinality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Occupation'\n",
    "dist_fig, relation_fig, ordinal_mi, onehot_mi = investigate_dem_feature(df, feature)\n",
    "dem_features_stats_df.loc[feature] = [ordinal_mi, onehot_mi, df_correlations[df_correlations[\"Feature\"] == feature][\"Correlation\"].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ordinal MI: {ordinal_mi}')\n",
    "print(f'One-hot MI: {onehot_mi}')\n",
    "print(f'Correlation: {dem_features_stats_df.loc[feature][\"Correlation\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The distribution shows a huge difference between how much are different occupations represented in the dataset.\n",
    "- The relation of the occupation to the target variable is almost non-existent.\n",
    "- The mutual information tests show a slight preference towards one-hot encoding, which aligns with our intuition of the variable's meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'City_Category'\n",
    "dist_fig, relation_fig, ordinal_mi, onehot_mi = investigate_dem_feature(df, feature)\n",
    "dem_features_stats_df.loc[feature] = [ordinal_mi, onehot_mi, df_correlations[df_correlations[\"Feature\"] == feature][\"Correlation\"].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ordinal MI: {ordinal_mi}')\n",
    "print(f'One-hot MI: {onehot_mi}')\n",
    "print(f'Correlation: {dem_features_stats_df.loc[feature][\"Correlation\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The distribution shows that city category B appears in the dataset slightly often, although the difference is not significant.\n",
    "- Again, the influence of the city category on the target variable is minimal.\n",
    "- The mutual information tests show a preference towards one hot encoding, which aligns with our intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years spent in current city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Stay_In_Current_City_Years'\n",
    "dist_fig, relation_fig, ordinal_mi, onehot_mi = investigate_dem_feature(df, feature)\n",
    "dem_features_stats_df.loc[feature] = [ordinal_mi, onehot_mi, df_correlations[df_correlations[\"Feature\"] == feature][\"Correlation\"].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ordinal MI: {ordinal_mi}')\n",
    "print(f'One-hot MI: {onehot_mi}')\n",
    "print(f'Correlation: {dem_features_stats_df.loc[feature][\"Correlation\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The most represented group is of 1 year with around twice as many purchases than it's successor.\n",
    "- The impact of the variable is negligible.\n",
    "- The mutual information tests show a preference towards one-hot encoding, despite the variable is intuitively ordinal. However, despite the ordinality of the variable itself, higher values don't necessarily imply any relations to the purchase amounts. Nevertheless, due to the very low correlation between the feature and the target variable, dropping the feature might seem like the best idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marital status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Marital_Status'\n",
    "dist_fig, relation_fig, ordinal_mi, onehot_mi = investigate_dem_feature(df, feature)\n",
    "dem_features_stats_df.loc[feature] = [ordinal_mi, onehot_mi, df_correlations[df_correlations[\"Feature\"] == feature][\"Correlation\"].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ordinal MI: {ordinal_mi}')\n",
    "print(f'One-hot MI: {onehot_mi}')\n",
    "print(f'Correlation: {dem_features_stats_df.loc[feature][\"Correlation\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The distribution plot and the feature variable-relation plot show nothing out of the ordinary.\n",
    "- Again, a very low correlation between the feature and the target variable suggests that the feature should not be used.\n",
    "- Since this variable is binary, mutual information tests correctly produce equal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key take aways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_features_stats_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the `Marital_Status` and `Stay_In_Current_City_Years` features, we observed almost no correlation, implying no relation with the target value, which was further confirmed by the mutual tests. Therefore, we will not use these features for training the model, reducing the complexity of the data.\n",
    "- The `Age` feature showed quite low correlation but yielded higher results in MI tests, suggesting that while there's no monotonic relationship between the feature variable and the target, the feature could contribute to explaining the target variable. The feature will be one-hot encoded per the results of the MI tests.\n",
    "- The `Occupation` feature yields relatively high values in both three measures, suggesting that it should be used as a predictor. Although the MI tests show that one-hot encoding the feature offers slightly more information, this step also introduces 21 input variables, greatly increasing the complexity of the data, hence ordinal encoding might be a better choice.\n",
    "- The `Gender` feature showed a relatively high correlation, making it a potentially solid predictor, which was confirmed by MI tests.\n",
    "- The `City_Category` features yielded the highest correlation among the demographic features. MI tests then showed that one-hot encoding the variable results in higher information yield."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of demographic features that will be used for the training, alongside with the preprocessing step:\n",
    "- **Age**: One-hot\n",
    "- **Occupation**: Ordinal\n",
    "- **Gender**: Binary\n",
    "- **City_Category**: One-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_regression(df[product_category_cols].fillna(0), df['Purchase'], random_state=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_regression(df_encoded.filter(regex='Product_Category*'), df['Purchase'], random_state=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `User_ID` column serves as a unique identifier of a user. It will not be used as an input for the model, however it can still offer interesting insights into the data.\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_purchase_count = df.groupby(by='User_ID')['Purchase']\\\n",
    "    .agg(['mean', 'std', 'count'])\\\n",
    "    .sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_purchase_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Product_ID` serves as a unique identifier for each product. It will not be used as an input feature. However, we can use it to better understand the dataset.\n",
    "\n",
    "The questions we want to answer are:\n",
    "- Are product categories constant among all purchases of a single product?\n",
    "- How much does the purchase amount vary for a single product among purchases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Product_ID'] + product_category_cols]\\\n",
    "    .fillna(0)\\\n",
    "    .groupby(by='Product_ID')[product_category_cols]\\\n",
    "    .nunique()\\\n",
    "    .eq(1)\\\n",
    "    .all()\\\n",
    "    .all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product categories are constant in all of the purchase instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='Product_ID')['Purchase']\\\n",
    "    .nunique()\\\n",
    "    .eq(1)\\\n",
    "    .all()\\\n",
    "    .all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purchase values are not constant among purchase instances. \n",
    "\n",
    "Let's investigate the differences in the most purchased products (for the sake of readability of the plot, we limit the amount of products to 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_products = 9\n",
    "\n",
    "products_purchase_count = df.groupby(by='Product_ID')['Purchase']\\\n",
    "    .agg(['mean', 'std', 'count'])\\\n",
    "    .sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    df[df['Product_ID'].isin(products_purchase_count.head(n_products).index)],\n",
    "    x='Product_ID',\n",
    "    y='Purchase',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Product ID of the most purchased products',\n",
    "    yaxis_title='Distribution of purchase amounts',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_n_cols = 3\n",
    "fig_n_rows = n_products // fig_n_cols + int(n_products % fig_n_cols != 0)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=fig_n_rows,\n",
    "    cols=fig_n_cols,\n",
    "    x_title='Purchase amount',\n",
    "    y_title='Number of occurrences',\n",
    "    subplot_titles=products_purchase_count.head(n_products).index.tolist(),\n",
    "    vertical_spacing=0.1,\n",
    ")\n",
    "\n",
    "for row_id in range(n_products):\n",
    "    product_id = products_purchase_count.index[row_id]\n",
    "\n",
    "    row = row_id // fig_n_cols\n",
    "    col = row_id % fig_n_cols\n",
    "\n",
    "    subplot = px.histogram(\n",
    "        df[df['Product_ID'] == product_id]['Purchase'],\n",
    "        nbins=100,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(subplot.data[0], row=row + 1, col=col + 1)\n",
    "\n",
    "fig.update_layout(showlegend=False, height=fig_n_rows * 300)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data show that there are heavy differences in the purchase amount for all of the products, and the purchase amounts of a product seem to follow somewhat normal distributions around 5 mean values. This could be explained by two reasons:\n",
    "- The different groups of purchase amounts exist because of discounts. Unfortunately, from the provided data, we have no way of checking whether this is true.\n",
    "- The purchase amounts differ based on the users' demographics. We investigate this behavior by the following.\n",
    "    - We compare users of the same demographics to the purchase value on the most purchased products.\n",
    "    - For users that bought several products, we check whether they always belong to the same price group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users of the same demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demographics_per_product(product_id: str) -> pd.DataFrame:\n",
    "    df_rel = df[df['Product_ID'] == product_id]\n",
    "\n",
    "    df_product_demographics = df_rel.copy()\n",
    "    df_product_demographics = df_product_demographics[feature_cols + ['Purchase']]\n",
    "\n",
    "    most_occuring_demographics = df_product_demographics.groupby(by=feature_cols)['Purchase'].count().sort_values(ascending=False).head(5).index\n",
    "\n",
    "    df_product_demographics = df_product_demographics.set_index(feature_cols)\n",
    "    df_product_demographics = df_product_demographics.loc[most_occuring_demographics, :]\n",
    "    df_product_demographics = df_product_demographics.sort_index()\n",
    "\n",
    "    for group, demographics in enumerate(most_occuring_demographics):\n",
    "        df_product_demographics.loc[demographics, 'Demographics group'] = group\n",
    "\n",
    "    df_product_demographics['Demographics group'] = df_product_demographics['Demographics group'].astype(int)\n",
    "\n",
    "    return df_product_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_demographics = get_demographics_per_product(products_purchase_count.index[1])\n",
    "\n",
    "df_product_demographics.groupby(by='Demographics group')['Purchase'].agg(['mean', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We substitute 5 of the most common demographic vectors with an integer representing the different groups.\n",
    "\n",
    "There are only a couple of users sharing the same demographics and their purchase amounts don't seem to differ heavily at the first glance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_product_demographics, x='Purchase', color='Demographics group')\n",
    "fig.update_layout(xaxis_title='Purchase amount', yaxis_title='Number of occurrences')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation of different demographic groups is somewhat uniform among the purchase amounts, however since only a very small number of users share the same demographics, the result isn't of large significance. Hence, we instead compare the demographic features to the purchase amounts separately for a single product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_n_cols = 2\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n_features // fig_n_cols + int(n_features % fig_n_cols != 0),\n",
    "    cols=fig_n_cols,\n",
    "    subplot_titles=feature_cols,\n",
    "    vertical_spacing=0.1,\n",
    "    horizontal_spacing=0.05,\n",
    "    x_title='Purchase amount',\n",
    "    y_title='Number of occurrences',\n",
    ")\n",
    "\n",
    "product_id = products_purchase_count.index[0]\n",
    "df_rel = df[df['Product_ID'] == product_id]\n",
    "\n",
    "for ith_feature in range(n_features):\n",
    "    feature = feature_cols[ith_feature]\n",
    "\n",
    "    row = ith_feature // fig_n_cols\n",
    "    col = ith_feature % fig_n_cols\n",
    "\n",
    "    subplot = px.histogram(\n",
    "        df_rel,\n",
    "        x='Purchase',\n",
    "        nbins=100,\n",
    "        category_orders={feature: sorted(df_rel[feature].unique())},\n",
    "        color=feature,\n",
    "    )\n",
    "\n",
    "    for trace_index, trace in enumerate(subplot.data):\n",
    "        trace.name = f\"{feature}: {trace.name}\"\n",
    "        fig.add_trace(trace, row=row+1, col=col+1)\n",
    "\n",
    "fig.update_layout(height=fig_n_rows * 300)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not seem to be a significant relationship between any of the features and the purchase amounts, which confirms the results of our correlation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users' purchase amount group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the analysis of demographic features did not explain the purchase amounts groups, we further investigate by analysing whether the grouping of the users is consistent, i.e. whether one user always buys products for small prices while another buys the same products for higher prices. \n",
    "\n",
    "To do this, we assume that there are always 5 price groups, which is an observation that seems true at least for products with many purchases. We then cluster purchases of each product and compare users' distributions of the clusters.\n",
    "\n",
    "We take into account only users with at least 100 purchases, and we eliminate products with less than 5 purchases to make the clustering possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df_clustered = df.copy()\n",
    "\n",
    "product_counts = df_clustered.value_counts('Product_ID')\n",
    "eligible_products = product_counts.index[product_counts.gt(5)]\n",
    "\n",
    "df_clustered = df_clustered.loc[df_clustered['Product_ID'].isin(eligible_products)]\n",
    "product_ids = df_clustered['Product_ID'].unique()\n",
    "\n",
    "for product_id in product_ids:\n",
    "    idx = df_clustered['Product_ID'] == product_id\n",
    "\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "    clusters = kmeans.fit_predict(df_clustered.loc[idx, ['Purchase']])\n",
    "\n",
    "    centroids = kmeans.cluster_centers_.flatten()\n",
    "    labels_ordered = np.argsort(centroids)\n",
    "    centroids_ordered = centroids[labels_ordered]\n",
    "\n",
    "    df_clustered.loc[idx, 'Cluster'] = clusters\n",
    "    df_clustered.loc[idx, 'Cluster'] = df_clustered.loc[idx, 'Cluster'].map({k: v for k, v in enumerate(labels_ordered)})\n",
    "    df_clustered.loc[idx, 'Cluster Centroid'] = df_clustered.loc[idx, 'Cluster'].map({k: v for k, v in enumerate(centroids_ordered)})\n",
    "\n",
    "df_clustered['Cluster'] = df_clustered['Cluster'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_users = users_purchase_count[users_purchase_count['count'].ge(100)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered_eligible = df_clustered[df_clustered['User_ID'].isin(eligible_users)]\n",
    "df_clustered_eligible.groupby('User_ID')['Cluster'].agg(['mean', 'std', 'count']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered_eligible['Cluster'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustered_eligible.groupby('User_ID')['Cluster'].agg(['mean', 'std', 'count'])['mean'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate product categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A product can fall into a minimum of one and a maximum of three categories, represented by columns `Product_Category_1`, `Product_Category_2` and `Product_Category_3`, where the second and third column have values missing. There are 20 different product categories, represented by integers from 1 to 20.\n",
    "\n",
    "The missing values need to be handled before entering a model, and we need to investigate the features to be able to handle them correctly, without corrupting the data in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by plotting the distribution of the number of categories a purchased product falls into. If most purchased products would fall into a maximum of, for example, 2 categories, we could simply decide to drop the mostly empty third column.\n",
    "\n",
    "Note that each purchase of a product is considered in this statistic, hence a single product can contribute several times to the total. This makes sense because of how will the data be handled within the model.\n",
    "\n",
    "The distribution of number of categories in purchased products looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df[product_category_cols].count(axis=1).value_counts(),\n",
    "    title='Distribution of number of categories in purchased products',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Number of categories',\n",
    "    yaxis_title='Number of purchases',\n",
    "    showlegend=False,\n",
    "    xaxis_tickvals=[1, 2, 3]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is somewhat uniform, with 2 categories per purchased product being slightly dominant. This means that by dropping a column, we could lose a significant amount of information.\n",
    "\n",
    "Another option is to fill the missing values with, for example, the most common value of that column. However, we don't know what do the values represent and if there's any relationship between them, hence filling the missing data with no further investigation could lead to biasing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=product_category_cols)['Purchase'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate users' purchasing behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate product-purchase relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[product_category_cols].corrwith(df['Purchase'], method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=product_category_cols[0])['Purchase'].agg(['mean', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Gender')['Purchase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
